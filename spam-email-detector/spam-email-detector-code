import numpy as py
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import joblib
import matplotlib.pyplot as plt
import seaborn as sns


df = pd.read_csv("SMSSpamCollection", sep="\t" ,encoding="latin-1", header=None, names=['label', 'text'])

df['label'] = df['label'].map({'ham': 0, 'spam': 1})
X_train, X_test, y_train, y_test = train_test_split(
    df['text'], df['label'], test_size=0.2, random_state=37
)

vectorizer = TfidfVectorizer(
    stop_words='english',
    ngram_range=(1, 3),    # unigrams, bigrams, trigrams
    min_df=2,              # ignore very rare words
    max_df=0.9             # ignore too frequent words
)
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)
model = MultinomialNB()
model.fit(X_train_vec, y_train)

y_pred=model.predict(X_test_vec)
cm = confusion_matrix(y_test, y_pred)
while True:
    msg = input("Enter a message (or type 'exit' to stop):")
    if msg.lower() == 'exit':
        break

    msg_vec = vectorizer.transform([msg])  # Convert input to TF-IDF
    bank_keywords = ['debited', 'credited', 'account', 'rs', 'transaction', 'otp']
    if any(word in msg.lower() for word in bank_keywords) and proba[1] > 0.15:
       print("ðŸŸ¥ [Rule-based flag] Suspicious Bank Message â†’ Likely SPAM")
    prediction = model.predict(msg_vec)[0]
    proba = model.predict_proba(msg_vec)[0]

    if proba[1] > 0.25:
       print("ðŸŸ¥ Prediction: SPAM")
       print(f"ðŸ§  Confidence â†’ HAM: {1-proba[0]:.2f}, SPAM: {1-proba[1]:.2f}") 
    elif proba[1]<=0.3:
       print("ðŸŸ© Prediction: HAM (Not Spam)")
       print(f"ðŸ§  Confidence â†’ HAM: {1-proba[1]:.2f}, SPAM: {1-proba[0]:.2f}") 
    
       
        
        
print(accuracy_score(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
joblib.dump(model, 'spam_model.pkl')
joblib.dump(vectorizer, 'vectorizer.pkl')

plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['HAM', 'SPAM'], yticklabels=['HAM', 'SPAM'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - Spam Detection')
labels = ['HAM', 'SPAM']
values = py.bincount(y_pred)

plt.bar(labels, values, color=['green', 'red'])
plt.title('Predicted Label Counts')
plt.ylabel('Number of Messages')

plt.show()
